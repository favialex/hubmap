{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 23: 23_added_labeled_data\n",
    "\n",
    "Average Test Dice: \n",
    "\n",
    "Public Leaderboard Score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"23_added_labeled_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import monai\n",
    "from monai.inferers import sliding_window_inference\n",
    "from typing import Union, Tuple, Any\n",
    "from pathlib import Path\n",
    "Path.ls = lambda p: list(p.iterdir())\n",
    "from functools import partial\n",
    "from fastai.data.transforms import get_image_files\n",
    "import catalyst\n",
    "from catalyst import dl\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "\n",
    "# Lookahead imports\n",
    "from typing import Callable, Dict, Optional\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(verbose: bool = True) -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        if verbose: print(\"Using the GPU!\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if verbose: print(\"Using the CPU!\")\n",
    "    return device\n",
    "    \n",
    "def load_image_monai(fn: Union[Path, str]) -> np.array:\n",
    "    image_array = monai.transforms.LoadImage(image_only=True)(str(fn))\n",
    "    return image_array.__array__().astype(np.uint8)\n",
    "\n",
    "def plot_image_mask(image: np.array, mask: np.array, figsize: Tuple[int, int] = (10, 10)):\n",
    "    if not isinstance(image, type(np.array([0]))): image = image.detach().cpu().numpy()\n",
    "    if not isinstance(mask, type(np.array([0]))): mask = mask.detach().cpu().numpy()\n",
    "    if len(image.shape) == 3 and image.shape[0] == 3: image = image.transpose(1, 2, 0)\n",
    "    if len(mask.shape) == 3 and mask.shape[0] > 1: mask = mask[0]\n",
    "    plt.figure(figsize=figsize)\n",
    "    if image.mean() > 1: plt.imshow(image.astype(np.uint8), interpolation=\"none\")\n",
    "    else: plt.imshow(image.astype(np.float32), interpolation=\"none\")\n",
    "    plt.imshow(mask.astype(np.uint8), cmap=\"jet\", alpha=0.5)\n",
    "    \n",
    "def plot_image(image: np.array, figsize: Tuple[int, int] = (10, 10)):\n",
    "    if not isinstance(image, type(np.array([0]))): image = image.detach().cpu().numpy()\n",
    "    if len(image.shape) == 3 and image.shape[0] == 3: image = image.transpose(1, 2, 0)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, interpolation=\"none\")\n",
    "\n",
    "def fn2image(fn: Union[Path, str]) -> np.array:\n",
    "    return load_image_monai(fn)\n",
    "\n",
    "def id2image(fid: str) -> np.array:\n",
    "    fn = id2fn(fid)\n",
    "    return fn2image(fn)\n",
    "\n",
    "def fn2id(fn: Union[Path, str]) -> str:\n",
    "    return str(fn).split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "def id2image(fid: str) -> np.array:\n",
    "    fn = id2fn(fid)\n",
    "    return fn2image(fn)\n",
    "\n",
    "def fn2id(fn: Union[Path, str]) -> str:\n",
    "    return str(fn).split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "def id2fn(fid: str) -> Path:\n",
    "    return COMBINED_DF[COMBINED_DF.id == int(fid)][\"fnames\"].values[0]\n",
    "\n",
    "def id2rle(fid: str) -> str:\n",
    "    rle = TRAIN_DF[TRAIN_DF.id==int(fid)][\"rle\"].values[0]\n",
    "    return rle\n",
    "\n",
    "def fn2rle(fn: Union[Path, str]) -> str:\n",
    "    fid = fn2id(fn)\n",
    "    return id2rle(fid)\n",
    "\n",
    "def id2organ(fid: str) -> str:\n",
    "    organ = TRAIN_DF[TRAIN_DF.id==int(fid)][\"organ\"].values[0]\n",
    "    return organ\n",
    "\n",
    "def id2shape(fid: str) -> Tuple[int, int]:\n",
    "    width = COMBINED_DF[COMBINED_DF.id==int(fid)][\"img_width\"].values[0]\n",
    "    height = COMBINED_DF[COMBINED_DF.id==int(fid)][\"img_height\"].values[0]\n",
    "    return width, height\n",
    "\n",
    "def fn2shape(fn: Union[Path, str]) -> Tuple[int, int]:\n",
    "    fid = fn2id(fn)\n",
    "    return id2shape(fid)\n",
    "\n",
    "def load_mask(fn: Union[Path, str]) -> np.array:\n",
    "    shape = fn2shape(fn)\n",
    "    rle = fn2rle(fn)\n",
    "    return rle_decode(rle, shape)\n",
    "\n",
    "def fn2mask(fn: Union[Path, str]) -> np.array:\n",
    "    return load_mask(fn)\n",
    "\n",
    "def id2mask(fid: str) -> np.array:\n",
    "    fn = id2fn(fid)\n",
    "    return fn2mask(fn)\n",
    "\n",
    "def save_df(df:Dict[str, Any], df_file:str, replace:bool=False):\n",
    "    if replace: return pd.DataFrame(df).to_csv(df_file, index=False)\n",
    "    try: \n",
    "        d = pd.read_csv(df_file)\n",
    "        d = pd.concat([d, pd.DataFrame(df)])\n",
    "    except FileNotFoundError: \n",
    "        d = pd.DataFrame(df)\n",
    "    d.to_csv(df_file, index=False)\n",
    "\n",
    "def load_df(df_file: str) -> pd.DataFrame:\n",
    "    try:  df = pd.read_csv(df_file)\n",
    "    except FileNotFoundError: df = None\n",
    "    return df\n",
    "\n",
    "def calc_metric(\n",
    "        y_hat:torch.Tensor,\n",
    "        y:torch.Tensor,\n",
    "        metric_func:callable,\n",
    "        process_logits:callable=monai.transforms.Compose([\n",
    "                monai.transforms.EnsureType(), \n",
    "                monai.transforms.Activations(softmax=True),\n",
    "                monai.transforms.AsDiscrete(argmax=True)\n",
    "            ])) -> float:\n",
    "    y_hat = [process_logits(i) for i in monai.data.decollate_batch(y_hat)]\n",
    "    y = [i for i in monai.data.decollate_batch(y)]\n",
    "    metric = metric_func(y_hat, y)\n",
    "    metric = metric_func.aggregate().item()\n",
    "    metric_func.reset()\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/code/paulorzp/run-length-encode-and-decode/script\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return np.reshape(img, shape)\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_train_test(df, colname, seed=9210, test_pct=0.2):\n",
    "    df = df.copy()\n",
    "    np.random.seed(seed)\n",
    "    indices = np.arange(len(df))\n",
    "    np.random.shuffle(indices)\n",
    "    test_ids = df.id.values[indices[:int(test_pct*len(indices))]]\n",
    "    df[colname] = df.id.apply(lambda fid: fid in test_ids)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lookahead(Optimizer):\n",
    "    \"\"\"Implements Lookahead algorithm.\n",
    "\n",
    "    It has been proposed in `Lookahead Optimizer: k steps forward,\n",
    "    1 step back`_.\n",
    "\n",
    "    Main origins of inspiration:\n",
    "        https://github.com/alphadl/lookahead.pytorch (MIT License)\n",
    "\n",
    "    .. _`Lookahead Optimizer\\: k steps forward, 1 step back`:\n",
    "        https://arxiv.org/abs/1907.08610\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, k: int = 5, alpha: float = 0.5):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.defaults = self.optimizer.defaults\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "\n",
    "\n",
    "    def update(self, group):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "\n",
    "\n",
    "    def update_lookahead(self):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "\n",
    "    def step(self, closure: Optional[Callable] = None):\n",
    "        \"\"\"Makes optimizer step.\n",
    "\n",
    "        Args:\n",
    "            closure (callable, optional): A closure that reevaluates\n",
    "                the model and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {\n",
    "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def get_from_params(\n",
    "        cls, params: Dict, base_optimizer_params: Dict = None, **kwargs,\n",
    "    ) -> \"Lookahead\":\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        from catalyst.dl.registry import OPTIMIZERS\n",
    "\n",
    "        base_optimizer = OPTIMIZERS.get_from_params(\n",
    "            params=params, **base_optimizer_params\n",
    "        )\n",
    "        optimizer = cls(optimizer=base_optimizer, **kwargs)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = pd.read_csv(\"../data/train.csv\")\n",
    "TEST_DF = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "TRAIN_IMAGES = get_image_files(\"../data/train_images\")\n",
    "TEST_IMAGES = get_image_files(\"../data/test_images\")\n",
    "ALL_IMAGES = [*TRAIN_IMAGES, *TEST_IMAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "KEYS = [\"image\", \"label\"]\n",
    "IMAGE = \"image\"\n",
    "LABEL = \"label\"\n",
    "DEVICE = get_device()\n",
    "TRANSFORM_PROB = 0.5\n",
    "CROP_SIZE = (2700, 2700)\n",
    "IMAGE_SIZE = (512, 512)\n",
    "MIN_CROP_SIZE = (160, 160) # Smallest imagesize in hidden testset (https://www.kaggle.com/competitions/hubmap-organ-segmentation/data)\n",
    "EPOCHS = 200\n",
    "ACCUM_STEPS = 1\n",
    "BATCH_SIZE = 16\n",
    "SW_ROISIZE = (160, 160)\n",
    "SW_BATCHSIZE = 4\n",
    "SW_OVERLAP = 0.5\n",
    "LR_BS = 4.6875e-05\n",
    "LR = LR_BS * BATCH_SIZE * ACCUM_STEPS\n",
    "EARLY_STOP_PATIENCE = 100\n",
    "ENCODER = \"efficientnet-b1\"\n",
    "GAUSS_STD = 0.8 * IMAGE_SIZE[0] / 1000 \n",
    "\n",
    "LOG_DIR = Path(\"../logs\")/EXP_NAME\n",
    "LOG_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fnames(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    fnames = []\n",
    "    for fid in df.id.values: fnames.append([fname for fname in ALL_IMAGES if str(fid) in fname.stem][0])\n",
    "    df[\"fnames\"] = fnames\n",
    "    return df\n",
    "\n",
    "def test_model(\n",
    "        model:torch.nn.Module, \n",
    "        dl:monai.data.DataLoader, \n",
    "        metric_func:callable, \n",
    "        threshold:float=0.5) -> float:\n",
    "    logit_process = monai.transforms.Compose([\n",
    "        monai.transforms.EnsureType(), \n",
    "        monai.transforms.Activations(softmax=True),\n",
    "        monai.transforms.AsDiscrete(threshold=threshold)\n",
    "    ])\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(dl), total=len(dl)):\n",
    "            X, y = data[IMAGE].to(DEVICE), data[LABEL]\n",
    "            y_hat = sw_infer(X, model).detach().cpu()\n",
    "            preds = [*preds, *[logit_process(i) for i in y_hat]]\n",
    "            trues = [*trues, *[i for i in monai.data.decollate_batch(y)]]\n",
    "    metric_func(preds, trues)\n",
    "    metric = metric_func.aggregate().item()\n",
    "    metric_func.reset()\n",
    "    return metric\n",
    "\n",
    "def load_weights(model:torch.nn.Module, weights_path:Union[str,Path], device:torch.device=DEVICE)->torch.nn.Module:\n",
    "    state_dict = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model.to(device)\n",
    "\n",
    "def make3D(t: np.array) -> np.array:\n",
    "    t = np.expand_dims(t, axis=2)\n",
    "    t = np.concatenate((t,t,t), axis=2)\n",
    "    return t\n",
    "\n",
    "def sw_infer(X:torch.Tensor, model:torch.nn.Module):\n",
    "    return model(X)\n",
    "    #return sliding_window_inference(X, SW_ROISIZE, SW_BATCHSIZE, model, overlap=SW_OVERLAP)\n",
    "\n",
    "def plot_results(model, dl, threshold=0.5, figsize=10):\n",
    "    logit_process = monai.transforms.Compose([\n",
    "        monai.transforms.EnsureType(), \n",
    "        monai.transforms.Activations(softmax=True),\n",
    "        monai.transforms.AsDiscrete(threshold=threshold)\n",
    "    ])\n",
    "    max_size = 2**16\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    ims, preds, labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(iter(dl), total=len(dl)):\n",
    "            X, y = item[IMAGE].to(DEVICE), item[LABEL].cpu()\n",
    "            y_hat = sw_infer(X, model).detach().cpu()\n",
    "            ims = [*ims, *[im.numpy() for im in X.detach().cpu()]]\n",
    "            preds = [*preds, *[logit_process(pred).numpy() for pred in y_hat]]\n",
    "            labels = [*labels, *[lbl.numpy() for lbl in y]]\n",
    "    \n",
    "    vs = []\n",
    "    for i, b in enumerate(range(len(preds))):\n",
    "        if (i+1) * preds[0].shape[1] * figsize > max_size:\n",
    "            print(\"Dataset to big, only displaying a portion of it!\")\n",
    "            break\n",
    "        \n",
    "        im = np.einsum(\"cwh->whc\", ims[b])\n",
    "        pred = make3D(preds[b][1])\n",
    "        label = make3D(labels[b][1])\n",
    "        vs.append(np.hstack((im, pred, label)))\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize*len(vs)))\n",
    "    plt.title(\"Input / Prediction / Target\")\n",
    "    plt.imshow(np.vstack(vs))\n",
    "\n",
    "def one_batch(\n",
    "        dl:monai.data.DataLoader, \n",
    "        b_idx:int=0, \n",
    "        unpacked:bool=False) -> Union[Dict[str, Any], Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    assert b_idx < len(dl), f\"DataLoader only has {len(dl)} batches...\"\n",
    "    for i, items in enumerate(iter(dl)):\n",
    "        if i == b_idx: \n",
    "            if unpacked:\n",
    "                X, y = items[IMAGE].to(DEVICE), items[LABEL].to(DEVICE)\n",
    "                return X, y\n",
    "            return items\n",
    "def batch2numpy(batch:Dict[str,torch.Tensor])->Tuple[np.array]:\n",
    "    return batch[IMAGE].detach().cpu().numpy(), batch[LABEL].detach().cpu().numpy()\n",
    "def plot_batch(batch:Dict[str, torch.Tensor], figsize:int=10):\n",
    "    X, y = batch2numpy(batch)\n",
    "    vstacks = []\n",
    "    for b in range(X.shape[0]):\n",
    "        im = X[b].transpose(1, 2, 0)\n",
    "        msk = make3D(y[b, 1])\n",
    "        vstacks.append(np.hstack((im,msk)))\n",
    "    patchwork = np.vstack(vstacks)\n",
    "    plt.figure(figsize=(figsize, figsize*X.shape[0]))\n",
    "    plt.imshow(patchwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10044.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>../data/train_images/10274.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     organ data_source  img_height  img_width  pixel_size  \\\n",
       "0  10044  prostate         HPA        3000       3000         0.4   \n",
       "1  10274  prostate         HPA        3000       3000         0.4   \n",
       "\n",
       "   tissue_thickness   age   sex                           fnames  \n",
       "0                 4  37.0  Male  ../data/train_images/10044.tiff  \n",
       "1                 4  76.0  Male  ../data/train_images/10274.tiff  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF = add_fnames(TRAIN_DF)\n",
    "TEST_DF = add_fnames(TEST_DF)\n",
    "COMBINED_DF = pd.concat([TRAIN_DF, TEST_DF])\n",
    "COMBINED_DF.drop(columns=\"rle\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_COMBINED_DF = None\n",
    "for organ in TRAIN_DF.organ.unique():\n",
    "    if ADD_COMBINED_DF is None:\n",
    "        ADD_COMBINED_DF = pd.read_csv(f\"../data/additional_images/{organ}.csv\")\n",
    "        continue\n",
    "    ADD_COMBINED_DF = pd.concat([ADD_COMBINED_DF, pd.read_csv(f\"../data/additional_images/{organ}.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alb_wrapper(arr, f):\n",
    "    datatype = arr.dtype\n",
    "    arr = torch.einsum(\"cwh->whc\", arr) * 255.\n",
    "    arr = f(image=arr.numpy().astype(np.uint8))[\"image\"]\n",
    "    arr = torch.Tensor(arr).to(datatype) / 255.\n",
    "    return torch.einsum(\"whc->cwh\", arr)\n",
    "huesat = partial(alb_wrapper, f=A.HueSaturationValue(\n",
    "    p=1, \n",
    "    hue_shift_limit=80,\n",
    "    sat_shift_limit=80, \n",
    "    val_shift_limit=80, \n",
    "    always_apply=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(model, dl, metric_func):\n",
    "    \n",
    "    thresholds = torch.linspace(0.1, 0.9, 17)\n",
    "    res, preds, trues = [], [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(dl), total=len(dl)):\n",
    "            X, y = data[IMAGE].to(DEVICE), data[LABEL]\n",
    "            y_hat = sw_infer(X, model).detach().cpu()\n",
    "            preds = [*preds, *[i for i in y_hat]]\n",
    "            trues = [*trues, *[i for i in monai.data.decollate_batch(y)]]\n",
    "    \n",
    "    for t in thresholds:\n",
    "        logit_process = monai.transforms.Compose([\n",
    "            monai.transforms.EnsureType(), \n",
    "            monai.transforms.Activations(softmax=True),\n",
    "            monai.transforms.AsDiscrete(threshold=t)\n",
    "        ])\n",
    "        metric_func([logit_process(i) for i in preds], trues)\n",
    "        metric = metric_func.aggregate().item()\n",
    "        metric_func.reset()\n",
    "        res.append((t.detach().cpu().item(), metric))\n",
    "\n",
    "    #for t in thresholds: res.append((t.detach().cpu().item(), test_model(model, dl, threshold=t, metric_func=metric_func)))\n",
    "    return sorted(res, key=lambda tpl: tpl[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data2rle(fn):\n",
    "    rle = ADD_COMBINED_DF[ADD_COMBINED_DF.fn==fn][\"rles\"].values[0]\n",
    "    try: rle = rle_decode(rle, IMAGE_SIZE)\n",
    "    except:\n",
    "        print(fn, rle)\n",
    "        assert False\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD_COMBINED_DF[ADD_COMBINED_DF.fn==\"../data/additional_images/images/ENSG00000113300_prostate_1.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = ADD_COMBINED_DF.dropna().fn.values[0]\n",
    "#last_fn = None\n",
    "#for fn in tqdm(ADD_COMBINED_DF.dropna().fn.values):\n",
    "#    last_fn = fn\n",
    "#    d = {IMAGE:fn, LABEL:fn}\n",
    "#    d = get_train_transforms()(d)\n",
    "\n",
    "#plt.imshow(np.hstack((d[IMAGE].numpy().mean(0),d[LABEL].numpy()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        monai.transforms.Lambdad((IMAGE,), id2image),\n",
    "        monai.transforms.TransposeD((IMAGE,), (2, 0, 1)),\n",
    "        monai.transforms.Lambdad((LABEL,), id2mask),\n",
    "        monai.transforms.AddChanneld((LABEL,)),\n",
    "        monai.transforms.AsDiscreted((LABEL,), to_onehot=2),\n",
    "        monai.transforms.ScaleIntensityD((IMAGE,)),\n",
    "    ])\n",
    "\n",
    "def get_added_data_load_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        monai.transforms.Lambdad((IMAGE,), load_image_monai),\n",
    "        monai.transforms.TransposeD((IMAGE,), (2, 0, 1)),\n",
    "        monai.transforms.Lambdad((LABEL,), add_data2rle),\n",
    "        monai.transforms.AddChanneld((LABEL,)),\n",
    "        monai.transforms.AsDiscreted((LABEL,), to_onehot=2),\n",
    "        monai.transforms.ScaleIntensityD((IMAGE,)),\n",
    "    ])\n",
    "\n",
    "def get_train_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        *get_added_data_load_transforms().transforms,\n",
    "        \n",
    "        #monai.transforms.RandSpatialCropd(KEYS, roi_size=MIN_CROP_SIZE, max_roi_size=CROP_SIZE),\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.RandRotated(KEYS, range_x=np.pi, prob=1, padding_mode=\"reflection\"),\n",
    "        monai.transforms.Lambdad((IMAGE,), huesat),\n",
    "        \n",
    "        monai.transforms.RandAdjustContrastd((IMAGE,), prob=TRANSFORM_PROB),\n",
    "        monai.transforms.RandGaussianNoised((IMAGE,), prob=TRANSFORM_PROB),\n",
    "        monai.transforms.RandCoarseShuffled((IMAGE,), \n",
    "            holes=2, \n",
    "            max_holes=15, \n",
    "            spatial_size=(int(IMAGE_SIZE[0]*0.01), int(IMAGE_SIZE[1]*0.01)), \n",
    "            max_spatial_size=(int(IMAGE_SIZE[0]*0.1), int(IMAGE_SIZE[1]*0.1)),  \n",
    "            prob=TRANSFORM_PROB),\n",
    "\n",
    "        monai.transforms.AsDiscreteD((LABEL,), threshold=0.5),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])\n",
    "\n",
    "def get_valid_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        *get_load_transforms().transforms,\n",
    "\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.RandRotated(KEYS, range_x=3.14159, prob=1, padding_mode=\"reflection\"),\n",
    "        monai.transforms.AsDiscreteD((LABEL,), threshold=0.5),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])\n",
    "\n",
    "def get_test_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        *get_load_transforms().transforms,\n",
    "\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"model_name\": [],\n",
    "    \"train_seed\": [], \n",
    "    \"train_size\": [], \n",
    "    \"threshold\": [], \n",
    "    \"test_dice\":[]}\n",
    "\n",
    "version = 2\n",
    "version_offset = int(100*version)\n",
    "epochs = 15\n",
    "organ = \"lung\"\n",
    "train_size = 0.05\n",
    "for train_seed in range(5):\n",
    "\n",
    "    train_seed += version_offset\n",
    "\n",
    "    add_organ_df = pd.read_csv(f\"../data/additional_images/{organ}_v{version}.csv\")\n",
    "    add_organ_df = add_organ_df.dropna()\n",
    "\n",
    "    indices = list(range(len(add_organ_df)))\n",
    "    np.random.seed(train_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    indices = indices[:int(len(indices)*train_size)]\n",
    "    train_data_dict = {i:{IMAGE:fn, LABEL:fn} for i, fn in enumerate(add_organ_df.fn.values[indices])}\n",
    "\n",
    "    organ_valid_test_df = split_df_train_test(TRAIN_DF[TRAIN_DF.organ==organ],\"is_test\", test_pct=0.5)\n",
    "    test_ids = organ_valid_test_df[organ_valid_test_df.is_test].id.values\n",
    "    valid_ids = organ_valid_test_df[~organ_valid_test_df.is_test].id.values\n",
    "\n",
    "    valid_data_dict = {i:{IMAGE:fid, LABEL:fid} for i, fid in enumerate(valid_ids)}\n",
    "    test_data_dict = {i:{IMAGE:fid, LABEL:fid} for i, fid in enumerate(test_ids)}\n",
    "\n",
    "    train_ds = monai.data.CacheDataset(train_data_dict, transform=get_train_transforms())\n",
    "    valid_ds = monai.data.CacheDataset(valid_data_dict, transform=get_valid_transforms())\n",
    "    test_ds  = monai.data.Dataset(test_data_dict,  transform=get_test_transforms())\n",
    "\n",
    "    train_dl = monai.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = monai.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_dl  = monai.data.DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    loaders = {\"train\": train_dl, \"valid\": valid_dl}\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,        \n",
    "        encoder_weights=\"imagenet\",     \n",
    "        in_channels=3,                  \n",
    "        classes=2,  \n",
    "    )\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    criterion = monai.losses.GeneralizedDiceFocalLoss(softmax=True)\n",
    "    optimizer = Lookahead(torch.optim.RAdam(model.parameters(), lr=LR))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, int(epochs*2))\n",
    "\n",
    "    dice_func = partial(\n",
    "        calc_metric, \n",
    "        metric_func=monai.metrics.DiceMetric(include_background=False, reduction=\"mean\"))\n",
    "\n",
    "    callbacks = [\n",
    "        catalyst.dl.FunctionalMetricCallback(\n",
    "        input_key=\"logits\",\n",
    "        target_key=LABEL,\n",
    "        metric_fn=dice_func,\n",
    "        metric_key=\"dice\"\n",
    "        ),\n",
    "        catalyst.dl.OptimizerCallback(\n",
    "            metric_key=\"loss\", \n",
    "            accumulation_steps=ACCUM_STEPS),\n",
    "        catalyst.dl.EarlyStoppingCallback(\n",
    "            patience=EARLY_STOP_PATIENCE, \n",
    "            loader_key=\"valid\", \n",
    "            metric_key=\"loss\",\n",
    "            min_delta=1e-3,\n",
    "            minimize=True)\n",
    "    ]\n",
    "\n",
    "    runner = catalyst.dl.SupervisedRunner(\n",
    "        input_key=IMAGE, \n",
    "        output_key=\"logits\", \n",
    "        target_key=LABEL, \n",
    "        loss_key=\"loss\"\n",
    "    )\n",
    "\n",
    "    model_name = f\"{organ}_v{train_seed}\"\n",
    "\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loaders=loaders,\n",
    "        num_epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        logdir=LOG_DIR/model_name,\n",
    "        valid_loader=\"valid\",\n",
    "        valid_metric=\"loss\",\n",
    "        minimize_valid_metric=True,\n",
    "        verbose=False,\n",
    "        timeit=False,\n",
    "        load_best_on_end=True\n",
    "    )\n",
    "\n",
    "    thres = get_best_threshold(model, test_dl, metric_func=monai.metrics.DiceMetric(include_background=False, reduction=\"mean\"))\n",
    "\n",
    "    model_metrics[\"model_name\"].append(model_name)\n",
    "    model_metrics[\"train_seed\"].append(train_seed)\n",
    "    model_metrics[\"train_size\"].append(train_size)\n",
    "    model_metrics[\"threshold\"].append(thres[0])\n",
    "    model_metrics[\"test_dice\"].append(thres[1])\n",
    "\n",
    "\n",
    "model_metrics = pd.DataFrame(model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = pd.DataFrame(model_metrics)\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(model, test_dl, threshold=thres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_stats = model_metrics.sort_values(\"test_dice\", ascending=False).iloc[0]\n",
    "best_model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_stats = {\"threshold\": 0.9, \"model_name\": \"lung_v1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gtex_load_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        monai.transforms.Lambdad(KEYS, load_image_monai),\n",
    "        monai.transforms.TransposeD(KEYS, (2, 0, 1)),\n",
    "        monai.transforms.ScaleIntensityD(KEYS),\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])\n",
    "\n",
    "def process_logits(y_hat, threshold):\n",
    "    logit_process = monai.transforms.Compose([\n",
    "        monai.transforms.EnsureType(), \n",
    "        monai.transforms.Activations(softmax=True),\n",
    "        monai.transforms.AsDiscrete(threshold=threshold)\n",
    "    ])\n",
    "    preds = []\n",
    "    y_hat = y_hat.detach().cpu()\n",
    "    preds = [*preds, *[logit_process(pred).numpy()[1] for pred in y_hat]]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ = \"lung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_organ = organ if organ != \"largeintestine\" else \"colon\"\n",
    "ADDITIONAL_IMAGES = get_image_files(\"../data/additional_images/images\")\n",
    "ADDITIONAL_IMAGES = [fn for fn in ADDITIONAL_IMAGES if add_organ in fn.stem]\n",
    "\n",
    "data_dict = {i: {IMAGE: add_im, LABEL: add_im} for i, add_im in enumerate(ADDITIONAL_IMAGES)}\n",
    "\n",
    "add_ds = monai.data.Dataset(data_dict, transform=get_gtex_load_transforms())\n",
    "add_dl = monai.data.DataLoader(add_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "p_model = f\"../logs/23_added_labeled_data/{best_model_stats['model_name']}/checkpoints/model.best.pth\"\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=2,  \n",
    ")\n",
    "model = load_weights(model, p_model)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/favi/work/kaggle/hubmap_reboot/nbs/23_added_labeled_data.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.2.36/home/favi/work/kaggle/hubmap_reboot/nbs/23_added_labeled_data.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plot_results(model, test_dl, threshold\u001b[39m=\u001b[39mbest_model_stats[\u001b[39m\"\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dl' is not defined"
     ]
    }
   ],
   "source": [
    "plot_results(model, test_dl, threshold=best_model_stats[\"threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1918/1918 [04:11<00:00,  7.61it/s]\n"
     ]
    }
   ],
   "source": [
    "rles, ims = [], []\n",
    "model.eval()\n",
    "for b in tqdm(iter(add_dl), total=len(add_dl)):\n",
    "    X = b[IMAGE].to(DEVICE)\n",
    "    y_hat = model(X)\n",
    "    rles = [*rles, *[rle_encode(pred) for pred in process_logits(y_hat, best_model_stats[\"threshold\"])]]\n",
    "\n",
    "add_fnames = [str(fn[IMAGE]) for fn in add_dl.dataset.data.values()]\n",
    "add_data_df = pd.DataFrame({\"fn\": add_fnames, \"rles\": rles})\n",
    "add_data_df.to_csv(f\"../data/additional_images/{organ}_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on added data, validate and test on original data\n",
    "\n",
    "\n",
    "\n",
    "organ = \"lung\"\n",
    "train_seed = 4\n",
    "train_size = 0.05\n",
    "\n",
    "add_organ_df = pd.read_csv(f\"../data/additional_images/{organ}.csv\")\n",
    "print(len(add_organ_df))\n",
    "add_organ_df = add_organ_df.dropna()\n",
    "print(len(add_organ_df))\n",
    "\n",
    "indices = list(range(len(add_organ_df)))\n",
    "np.random.seed(train_seed)\n",
    "np.random.shuffle(indices)\n",
    "indices = indices[:int(len(indices)*train_size)]\n",
    "train_data_dict = {i:{IMAGE:fn, LABEL:fn} for i, fn in enumerate(add_organ_df.fn.values[indices])}\n",
    "\n",
    "organ_valid_test_df = split_df_train_test(TRAIN_DF[TRAIN_DF.organ==organ],\"is_test\", test_pct=0.5)\n",
    "test_ids = organ_valid_test_df[organ_valid_test_df.is_test].id.values\n",
    "valid_ids = organ_valid_test_df[~organ_valid_test_df.is_test].id.values\n",
    "\n",
    "valid_data_dict = {i:{IMAGE:fid, LABEL:fid} for i, fid in enumerate(valid_ids)}\n",
    "test_data_dict = {i:{IMAGE:fid, LABEL:fid} for i, fid in enumerate(test_ids)}\n",
    "\n",
    "train_ds = monai.data.CacheDataset(train_data_dict, transform=get_train_transforms())\n",
    "valid_ds = monai.data.CacheDataset(valid_data_dict, transform=get_valid_transforms())\n",
    "test_ds  = monai.data.Dataset(test_data_dict,  transform=get_test_transforms())\n",
    "\n",
    "train_dl = monai.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dl = monai.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl  = monai.data.DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_dl, \"valid\": valid_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=2,  \n",
    ")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = monai.losses.GeneralizedDiceFocalLoss(softmax=True)\n",
    "optimizer = Lookahead(torch.optim.RAdam(model.parameters(), lr=LR))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5)\n",
    "\n",
    "dice_func = partial(\n",
    "    calc_metric, \n",
    "    metric_func=monai.metrics.DiceMetric(include_background=False, reduction=\"mean\"))\n",
    "\n",
    "callbacks = [\n",
    "    catalyst.dl.FunctionalMetricCallback(\n",
    "    input_key=\"logits\",\n",
    "    target_key=LABEL,\n",
    "    metric_fn=dice_func,\n",
    "    metric_key=\"dice\"\n",
    "    ),\n",
    "    catalyst.dl.OptimizerCallback(\n",
    "        metric_key=\"loss\", \n",
    "        accumulation_steps=ACCUM_STEPS),\n",
    "    catalyst.dl.EarlyStoppingCallback(\n",
    "        patience=EARLY_STOP_PATIENCE, \n",
    "        loader_key=\"valid\", \n",
    "        metric_key=\"loss\",\n",
    "        min_delta=1e-3,\n",
    "        minimize=True)\n",
    "]\n",
    "\n",
    "runner = catalyst.dl.SupervisedRunner(\n",
    "    input_key=IMAGE, \n",
    "    output_key=\"logits\", \n",
    "    target_key=LABEL, \n",
    "    loss_key=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_added_data_load_transforms()({'image': '../data/additional_images/images/ENSG00000130165_lung_0.jpg', 'label': '../data/additional_images/images/ENSG00000130165_lung_0.jpg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in tqdm(train_dl.dataset.data):\n",
    "#    d = train_dl.dataset.data[d]\n",
    "#    get_added_data_load_transforms()(d[IMAGE])\n",
    "    #try: get_added_data_load_transforms()(d[IMAGE])\n",
    "    ##except: \n",
    "    #    print(d)\n",
    "    #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_data2rle(\"../data/additional_images/images/ENSG00000130165_lung_0.jpg\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterdl = iter(train_dl)\n",
    "#for b in iterdl:\n",
    "#    X, y = b[IMAGE].to(DEVICE), b[LABEL].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    num_epochs=5,\n",
    "    callbacks=callbacks,\n",
    "    logdir=LOG_DIR/f\"{organ}_finetuned\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "    timeit=False,\n",
    "    load_best_on_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = get_best_threshold(model, test_dl, metric_func=monai.metrics.DiceMetric(include_background=False, reduction=\"mean\"))\n",
    "thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seed: 3 -> test dice: 0.19762\n",
    "\n",
    "seed: 0 -> test dice: 0.19624\n",
    "\n",
    "seed: 2 -> test dice: 0.19212\n",
    "\n",
    "\n",
    "seed: 1 -> test dice: 0.18086\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(model, test_dl, threshold=thres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hubmap_reboot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a41d83ab1b5d99694b0e2755cc1a9092b5b6bb1cb85044d4c03a072b08ac20f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
