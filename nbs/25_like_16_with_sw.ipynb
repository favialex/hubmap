{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 25: 25_like_16_with_sw\n",
    "\n",
    "Average Test Dice: \n",
    "\n",
    "Public Leaderboard Score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"25_like_16_with_sw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "from monai.inferers import sliding_window_inference\n",
    "from typing import Union, Tuple, Any\n",
    "from pathlib import Path\n",
    "Path.ls = lambda p: list(p.iterdir())\n",
    "from functools import partial\n",
    "from fastai.data.transforms import get_image_files\n",
    "import catalyst\n",
    "from catalyst import dl\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "\n",
    "# Lookahead imports\n",
    "from typing import Callable, Dict, Optional\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(verbose: bool = True) -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        if verbose: print(\"Using the GPU!\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if verbose: print(\"Using the CPU!\")\n",
    "    return device\n",
    "    \n",
    "def load_image_monai(fn: Union[Path, str]) -> np.array:\n",
    "    image_array = monai.transforms.LoadImage(image_only=True)(str(fn))\n",
    "    return image_array.__array__().astype(np.uint8)\n",
    "\n",
    "def plot_image_mask(image: np.array, mask: np.array, figsize: Tuple[int, int] = (10, 10)):\n",
    "    if not isinstance(image, type(np.array([0]))): image = image.detach().cpu().numpy()\n",
    "    if not isinstance(mask, type(np.array([0]))): mask = mask.detach().cpu().numpy()\n",
    "    if len(image.shape) == 3 and image.shape[0] == 3: image = image.transpose(1, 2, 0)\n",
    "    if len(mask.shape) == 3 and mask.shape[0] > 1: mask = mask[0]\n",
    "    plt.figure(figsize=figsize)\n",
    "    if image.mean() > 1: plt.imshow(image.astype(np.uint8), interpolation=\"none\")\n",
    "    else: plt.imshow(image.astype(np.float32), interpolation=\"none\")\n",
    "    plt.imshow(mask.astype(np.uint8), cmap=\"jet\", alpha=0.5)\n",
    "    \n",
    "def plot_image(image: np.array, figsize: Tuple[int, int] = (10, 10)):\n",
    "    if not isinstance(image, type(np.array([0]))): image = image.detach().cpu().numpy()\n",
    "    if len(image.shape) == 3 and image.shape[0] == 3: image = image.transpose(1, 2, 0)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, interpolation=\"none\")\n",
    "\n",
    "def fn2image(fn: Union[Path, str]) -> np.array:\n",
    "    return load_image_monai(fn)\n",
    "\n",
    "def id2image(fid: str) -> np.array:\n",
    "    fn = id2fn(fid)\n",
    "    return fn2image(fn)\n",
    "\n",
    "def fn2id(fn: Union[Path, str]) -> str:\n",
    "    return str(fn).split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "def id2image(fid: str) -> np.array:\n",
    "    fn = id2fn(fid)\n",
    "    return fn2image(fn)\n",
    "\n",
    "def fn2id(fn: Union[Path, str]) -> str:\n",
    "    return str(fn).split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "def id2fn(fid: str) -> Path:\n",
    "    return COMBINED_DF[COMBINED_DF.id == int(fid)][\"fnames\"].values[0]\n",
    "\n",
    "def id2rle(fid: str) -> str:\n",
    "    rle = TRAIN_DF[TRAIN_DF.id==int(fid)][\"rle\"].values[0]\n",
    "    return rle\n",
    "\n",
    "def fn2rle(fn: Union[Path, str]) -> str:\n",
    "    fid = fn2id(fn)\n",
    "    return id2rle(fid)\n",
    "\n",
    "def id2organ(fid: str) -> str:\n",
    "    organ = TRAIN_DF[TRAIN_DF.id==int(fid)][\"organ\"].values[0]\n",
    "    return organ\n",
    "\n",
    "def id2shape(fid: str) -> Tuple[int, int]:\n",
    "    width = COMBINED_DF[COMBINED_DF.id==int(fid)][\"img_width\"].values[0]\n",
    "    height = COMBINED_DF[COMBINED_DF.id==int(fid)][\"img_height\"].values[0]\n",
    "    return width, height\n",
    "\n",
    "def fn2shape(fn: Union[Path, str]) -> Tuple[int, int]:\n",
    "    fid = fn2id(fn)\n",
    "    return id2shape(fid)\n",
    "\n",
    "def load_mask(fn: Union[Path, str]) -> np.array:\n",
    "    shape = fn2shape(fn)\n",
    "    rle = fn2rle(fn)\n",
    "    return rle_decode(rle, shape)\n",
    "\n",
    "def fn2mask(fn: Union[Path, str]) -> np.array:\n",
    "    return load_mask(fn)\n",
    "\n",
    "def id2mask(fid: str) -> np.array:\n",
    "    fn = id2fn(fid)\n",
    "    return fn2mask(fn)\n",
    "\n",
    "def save_df(df:Dict[str, Any], df_file:str, replace:bool=False):\n",
    "    if replace: return pd.DataFrame(df).to_csv(df_file, index=False)\n",
    "    try: \n",
    "        d = pd.read_csv(df_file)\n",
    "        d = pd.concat([d, pd.DataFrame(df)])\n",
    "    except FileNotFoundError: \n",
    "        d = pd.DataFrame(df)\n",
    "    d.to_csv(df_file, index=False)\n",
    "\n",
    "def load_df(df_file: str) -> pd.DataFrame:\n",
    "    try:  df = pd.read_csv(df_file)\n",
    "    except FileNotFoundError: df = None\n",
    "    return df\n",
    "\n",
    "def calc_metric(\n",
    "        y_hat:torch.Tensor,\n",
    "        y:torch.Tensor,\n",
    "        metric_func:callable,\n",
    "        process_logits:callable=monai.transforms.Compose([\n",
    "                monai.transforms.EnsureType(), \n",
    "                monai.transforms.Activations(softmax=True),\n",
    "                monai.transforms.AsDiscrete(argmax=True)\n",
    "            ])) -> float:\n",
    "    y_hat = [process_logits(i) for i in monai.data.decollate_batch(y_hat)]\n",
    "    y = [i for i in monai.data.decollate_batch(y)]\n",
    "    metric = metric_func(y_hat, y)\n",
    "    metric = metric_func.aggregate().item()\n",
    "    metric_func.reset()\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/code/paulorzp/run-length-encode-and-decode/script\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return np.reshape(img, shape)\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_train_test(df, colname, seed=9210, test_pct=0.2):\n",
    "    df = df.copy()\n",
    "    np.random.seed(seed)\n",
    "    indices = np.arange(len(df))\n",
    "    np.random.shuffle(indices)\n",
    "    test_ids = df.id.values[indices[:int(test_pct*len(indices))]]\n",
    "    df[colname] = df.id.apply(lambda fid: fid in test_ids)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lookahead(Optimizer):\n",
    "    \"\"\"Implements Lookahead algorithm.\n",
    "\n",
    "    It has been proposed in `Lookahead Optimizer: k steps forward,\n",
    "    1 step back`_.\n",
    "\n",
    "    Main origins of inspiration:\n",
    "        https://github.com/alphadl/lookahead.pytorch (MIT License)\n",
    "\n",
    "    .. _`Lookahead Optimizer\\: k steps forward, 1 step back`:\n",
    "        https://arxiv.org/abs/1907.08610\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, k: int = 5, alpha: float = 0.5):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.defaults = self.optimizer.defaults\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "\n",
    "\n",
    "    def update(self, group):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "\n",
    "\n",
    "    def update_lookahead(self):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "\n",
    "    def step(self, closure: Optional[Callable] = None):\n",
    "        \"\"\"Makes optimizer step.\n",
    "\n",
    "        Args:\n",
    "            closure (callable, optional): A closure that reevaluates\n",
    "                the model and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {\n",
    "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def get_from_params(\n",
    "        cls, params: Dict, base_optimizer_params: Dict = None, **kwargs,\n",
    "    ) -> \"Lookahead\":\n",
    "        \"\"\"@TODO: Docs. Contribution is welcome.\"\"\"\n",
    "        from catalyst.dl.registry import OPTIMIZERS\n",
    "\n",
    "        base_optimizer = OPTIMIZERS.get_from_params(\n",
    "            params=params, **base_optimizer_params\n",
    "        )\n",
    "        optimizer = cls(optimizer=base_optimizer, **kwargs)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = pd.read_csv(\"../data/train.csv\")\n",
    "TEST_DF = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "TRAIN_IMAGES = get_image_files(\"../data/train_images\")\n",
    "TEST_IMAGES = get_image_files(\"../data/test_images\")\n",
    "ALL_IMAGES = [*TRAIN_IMAGES, *TEST_IMAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = [\"image\", \"label\"]\n",
    "IMAGE = \"image\"\n",
    "LABEL = \"label\"\n",
    "DEVICE = get_device()\n",
    "TRANSFORM_PROB = 0.5\n",
    "CROP_SIZE = (2700, 2700)\n",
    "IMAGE_SIZE = (512, 512)\n",
    "MIN_CROP_SIZE = (160, 160) # Smallest imagesize in hidden testset (https://www.kaggle.com/competitions/hubmap-organ-segmentation/data)\n",
    "EPOCHS = 200\n",
    "ACCUM_STEPS = 1\n",
    "BATCH_SIZE = 8\n",
    "LR_BS = 4.6875e-05\n",
    "LR = LR_BS * BATCH_SIZE * ACCUM_STEPS\n",
    "EARLY_STOP_PATIENCE = 100\n",
    "ENCODER = \"efficientnet-b5\"\n",
    "GAUSS_STD = 0.8 * IMAGE_SIZE[0] / 1000 \n",
    "\n",
    "# Sliding window settings\n",
    "SW_ROISIZE = (160, 160)\n",
    "SW_BATCHSIZE = 4\n",
    "SW_OVERLAP = 0.5\n",
    "\n",
    "LOG_DIR = Path(\"../logs\")/EXP_NAME\n",
    "LOG_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sw_infer(X:torch.Tensor, model:torch.nn.Module):\n",
    "    return sliding_window_inference(X, SW_ROISIZE, SW_BATCHSIZE, model, overlap=SW_OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fnames(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    fnames = []\n",
    "    for fid in df.id.values: fnames.append([fname for fname in ALL_IMAGES if str(fid) in fname.stem][0])\n",
    "    df[\"fnames\"] = fnames\n",
    "    return df\n",
    "\n",
    "def test_model(\n",
    "        model:torch.nn.Module, \n",
    "        dl:monai.data.DataLoader, \n",
    "        metric_func:callable, \n",
    "        threshold:float=0.5) -> float:\n",
    "    logit_process = monai.transforms.Compose([\n",
    "        monai.transforms.EnsureType(), \n",
    "        monai.transforms.Activations(softmax=True),\n",
    "        monai.transforms.AsDiscrete(threshold=threshold)\n",
    "    ])\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(dl), total=len(dl)):\n",
    "            X, y = data[IMAGE].to(DEVICE), data[LABEL]\n",
    "            y_hat = sw_infer(X, model).detach().cpu()\n",
    "            preds = [*preds, *[logit_process(i) for i in y_hat]]\n",
    "            trues = [*trues, *[i for i in monai.data.decollate_batch(y)]]\n",
    "    metric_func(preds, trues)\n",
    "    metric = metric_func.aggregate().item()\n",
    "    metric_func.reset()\n",
    "    return metric\n",
    "\n",
    "def load_weights(model:torch.nn.Module, weights_path:Union[str,Path], device:torch.device=DEVICE)->torch.nn.Module:\n",
    "    state_dict = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model.to(device)\n",
    "\n",
    "def make3D(t: np.array) -> np.array:\n",
    "    t = np.expand_dims(t, axis=2)\n",
    "    t = np.concatenate((t,t,t), axis=2)\n",
    "    return t\n",
    "\n",
    "def plot_results(model, dl, threshold=0.5, figsize=10):\n",
    "    logit_process = monai.transforms.Compose([\n",
    "        monai.transforms.EnsureType(), \n",
    "        monai.transforms.Activations(softmax=True),\n",
    "        monai.transforms.AsDiscrete(threshold=threshold)\n",
    "    ])\n",
    "    max_size = 2**16\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    ims, preds, labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(iter(dl), total=len(dl)):\n",
    "            X, y = item[IMAGE].to(DEVICE), item[LABEL].cpu()\n",
    "            y_hat = sw_infer(X, model).detach().cpu()\n",
    "            #y_hat = model(X).detach().cpu()\n",
    "            ims = [*ims, *[im.numpy() for im in X.detach().cpu()]]\n",
    "            preds = [*preds, *[logit_process(pred).numpy() for pred in y_hat]]\n",
    "            labels = [*labels, *[lbl.numpy() for lbl in y]]\n",
    "    \n",
    "    vs = []\n",
    "    for i, b in enumerate(range(len(preds))):\n",
    "        if (i+1) * preds[0].shape[1] * figsize > max_size:\n",
    "            print(\"Dataset to big, only displaying a portion of it!\")\n",
    "            break\n",
    "        \n",
    "        im = np.einsum(\"cwh->whc\", ims[b])\n",
    "        pred = make3D(preds[b][1])\n",
    "        label = make3D(labels[b][1])\n",
    "        vs.append(np.hstack((im, pred, label)))\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize*len(vs)))\n",
    "    plt.title(\"Input / Prediction / Target\")\n",
    "    plt.imshow(np.vstack(vs))\n",
    "\n",
    "def one_batch(\n",
    "        dl:monai.data.DataLoader, \n",
    "        b_idx:int=0, \n",
    "        unpacked:bool=False) -> Union[Dict[str, Any], Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    assert b_idx < len(dl), f\"DataLoader only has {len(dl)} batches...\"\n",
    "    for i, items in enumerate(iter(dl)):\n",
    "        if i == b_idx: \n",
    "            if unpacked:\n",
    "                X, y = items[IMAGE].to(DEVICE), items[LABEL].to(DEVICE)\n",
    "                return X, y\n",
    "            return items\n",
    "def batch2numpy(batch:Dict[str,torch.Tensor])->Tuple[np.array]:\n",
    "    return batch[IMAGE].detach().cpu().numpy(), batch[LABEL].detach().cpu().numpy()\n",
    "def plot_batch(batch:Dict[str, torch.Tensor], figsize:int=10):\n",
    "    X, y = batch2numpy(batch)\n",
    "    vstacks = []\n",
    "    for b in range(X.shape[0]):\n",
    "        im = X[b].transpose(1, 2, 0)\n",
    "        msk = make3D(y[b, 1])\n",
    "        vstacks.append(np.hstack((im,msk)))\n",
    "    patchwork = np.vstack(vstacks)\n",
    "    plt.figure(figsize=(figsize, figsize*X.shape[0]))\n",
    "    plt.imshow(patchwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = add_fnames(TRAIN_DF)\n",
    "TEST_DF = add_fnames(TEST_DF)\n",
    "COMBINED_DF = pd.concat([TRAIN_DF, TEST_DF])\n",
    "COMBINED_DF.drop(columns=\"rle\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(arr):\n",
    "    noisy_arr = arr + torch.randn(*arr.shape)*GAUSS_STD\n",
    "    return noisy_arr.to(arr.dtype)\n",
    "\n",
    "def get_noisy_transforms()->monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        # Load the same image in 'image' and 'label' \n",
    "        monai.transforms.Lambdad(KEYS, fn2image),\n",
    "        monai.transforms.TransposeD(KEYS, (2, 0, 1)),\n",
    "        monai.transforms.ScaleIntensityD(KEYS),\n",
    "        monai.transforms.RandSpatialCropd(KEYS, roi_size=MIN_CROP_SIZE),\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"bilinear\")),\n",
    "        monai.transforms.RandRotated(KEYS, range_x=np.pi, prob=1, padding_mode=\"reflection\"),\n",
    "        monai.transforms.Lambdad(IMAGE, add_gaussian_noise),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_noisy_image(noise_im, im, figsize=10):\n",
    "    noise_im, im = noise_im.numpy(), im.numpy()\n",
    "    noise_im, im = noise_im.transpose(1, 2, 0), im.transpose(1, 2, 0)\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.imshow(np.hstack((noise_im, im)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = np.random.choice(COMBINED_DF.fnames.values)\n",
    "d = {IMAGE:fn,LABEL:fn}\n",
    "d = get_noisy_transforms()(d)\n",
    "plot_image_noisy_image(d[IMAGE], d[LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([16, 1, 16, 16])\n",
    "y = x * 0.75\n",
    "data_range = x.max().unsqueeze(0)\n",
    "monai.losses.ssim_loss.SSIMLoss()(x,y,data_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAELOSS(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l = torch.nn.L1Loss()\n",
    "        self.s = torch.sigmoid\n",
    "    def forward(self, y_hat, y): return self.l(self.s(y_hat), y)\n",
    "y_hat, y = torch.rand(2, 3, 256, 256), torch.rand(2, 3, 256, 256)\n",
    "MAELOSS()(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSIMLossWrapper(torch.nn.Module):\n",
    "    def __init__(self, sigmoid=True, include_background=True):\n",
    "        super().__init__()\n",
    "        self.l = monai.losses.ssim_loss.SSIMLoss(spatial_dims=2)\n",
    "        self.s = torch.sigmoid\n",
    "        self.apply_sigmoid = sigmoid\n",
    "        self.include_background = include_background\n",
    "    def forward(self, y_hat, y):\n",
    "        loss = 0\n",
    "        for channel in range(y_hat.shape[1]):\n",
    "            if not self.include_background and channel == 0: continue\n",
    "            if self.apply_sigmoid: p = self.s(y_hat[:,channel].unsqueeze(1))\n",
    "            else: p = y_hat[:,channel].unsqueeze(1)\n",
    "            t = y[:,channel].unsqueeze(1)\n",
    "            dr = p.max().unsqueeze(0) - p.min().unsqueeze(0)\n",
    "            if self.include_background: loss += self.l(p, t, dr) / y_hat.shape[1]\n",
    "            else: loss += self.l(p, t, dr) / (y_hat.shape[1] - 1)\n",
    "        return loss\n",
    "SSIMLossWrapper(sigmoid=False)(y_hat, y), SSIMLossWrapper(sigmoid=True)(y_hat, y), SSIMLossWrapper(sigmoid=False, include_background=False)(y_hat, y),\n",
    "#SSIMLossWrapper(sigmoid=False)(torch.ones([1,1,10,10])/2, torch.ones([1,1,10,10])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(torch.nn.Module):\n",
    "    def __init__(self, sigmoid=True):\n",
    "        super().__init__()\n",
    "        self.ssim = SSIMLossWrapper(sigmoid=sigmoid)\n",
    "        self.mae = MAELOSS()\n",
    "    def forward(self, y_hat, y): \n",
    "        return self.ssim(y_hat, y) + self.mae(y_hat, y)\n",
    "CombinedLoss()(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSIMGDICEFOCAL(torch.nn.Module):\n",
    "    def __init__(self, sigmoid=True, include_background=True):\n",
    "        super().__init__()\n",
    "        self.ssim = SSIMLossWrapper(sigmoid=sigmoid, include_background=include_background)\n",
    "        self.gdice_focal = monai.losses.GeneralizedDiceFocalLoss(softmax=True)\n",
    "    def forward(self, y_hat, y):\n",
    "        return self.gdice_focal(y_hat, y) + self.ssim(y_hat, y) \n",
    "SSIMGDICEFOCAL()(y_hat, y), SSIMGDICEFOCAL(sigmoid=False, include_background=True)(y_hat, y), SSIMGDICEFOCAL(sigmoid=True, include_background=False)(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alb_wrapper(arr, f):\n",
    "    datatype = arr.dtype\n",
    "    arr = torch.einsum(\"cwh->whc\", arr) * 255.\n",
    "    arr = f(image=arr.numpy().astype(np.uint8))[\"image\"]\n",
    "    arr = torch.Tensor(arr).to(datatype) / 255.\n",
    "    return torch.einsum(\"whc->cwh\", arr)\n",
    "huesat = partial(alb_wrapper, f=A.HueSaturationValue(\n",
    "    p=1, \n",
    "    hue_shift_limit=80,\n",
    "    sat_shift_limit=80, \n",
    "    val_shift_limit=80, \n",
    "    always_apply=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        monai.transforms.Lambdad((IMAGE,), id2image),\n",
    "        monai.transforms.TransposeD((IMAGE,), (2, 0, 1)),\n",
    "        monai.transforms.Lambdad((LABEL,), id2mask),\n",
    "        monai.transforms.AddChanneld((LABEL,)),\n",
    "        monai.transforms.AsDiscreted((LABEL,), to_onehot=2),\n",
    "        monai.transforms.ScaleIntensityD((IMAGE,)),\n",
    "    ])\n",
    "\n",
    "def get_train_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        *get_load_transforms().transforms,\n",
    "\n",
    "        monai.transforms.CenterSpatialCropd(KEYS,roi_size=CROP_SIZE),\n",
    "        \n",
    "        monai.transforms.RandSpatialCropd(KEYS, roi_size=MIN_CROP_SIZE, max_roi_size=CROP_SIZE),\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.RandRotated(KEYS, range_x=3.14159, prob=1, padding_mode=\"reflection\"),\n",
    "        monai.transforms.Lambdad((IMAGE,), huesat),\n",
    "        \n",
    "        monai.transforms.RandAdjustContrastd((IMAGE,), prob=TRANSFORM_PROB),\n",
    "        monai.transforms.RandGaussianNoised((IMAGE,), prob=TRANSFORM_PROB),\n",
    "        monai.transforms.RandCoarseShuffled((IMAGE,), \n",
    "            holes=2, \n",
    "            max_holes=15, \n",
    "            spatial_size=(int(IMAGE_SIZE[0]*0.01), int(IMAGE_SIZE[1]*0.01)), \n",
    "            max_spatial_size=(int(IMAGE_SIZE[0]*0.1), int(IMAGE_SIZE[1]*0.1)),  \n",
    "            prob=TRANSFORM_PROB),\n",
    "\n",
    "        monai.transforms.AsDiscreteD((LABEL,), threshold=0.5),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])\n",
    "\n",
    "def get_valid_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        monai.transforms.Lambdad((IMAGE,), id2image),\n",
    "        monai.transforms.TransposeD((IMAGE,), (2, 0, 1)),\n",
    "        monai.transforms.Lambdad((LABEL,), id2mask),\n",
    "        monai.transforms.AddChanneld((LABEL,)),\n",
    "        monai.transforms.AsDiscreted((LABEL,), to_onehot=2),\n",
    "        monai.transforms.ScaleIntensityD((IMAGE,)),\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.RandRotated(KEYS, range_x=3.14159, prob=1, padding_mode=\"reflection\"),\n",
    "        monai.transforms.AsDiscreteD((LABEL,), threshold=0.5),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])\n",
    "\n",
    "def get_test_transforms() -> monai.transforms.Compose:\n",
    "    return monai.transforms.Compose([\n",
    "        monai.transforms.Lambdad((IMAGE,), id2image),\n",
    "        monai.transforms.TransposeD((IMAGE,), (2, 0, 1)),\n",
    "        monai.transforms.Lambdad((LABEL,), id2mask),\n",
    "        monai.transforms.AddChanneld((LABEL,)),\n",
    "        monai.transforms.AsDiscreted((LABEL,), to_onehot=2),\n",
    "        monai.transforms.ScaleIntensityD((IMAGE,)),\n",
    "        monai.transforms.ResizeD(KEYS, spatial_size=IMAGE_SIZE, mode=(\"bilinear\", \"nearest-exact\")),\n",
    "        monai.transforms.EnsureTypeD(KEYS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(model, dl, metric_func):\n",
    "    \n",
    "    thresholds = torch.linspace(0.1, 0.9, 17)\n",
    "    res, preds, trues = [], [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(dl), total=len(dl)):\n",
    "            X, y = data[IMAGE].to(DEVICE), data[LABEL]\n",
    "            y_hat = sw_infer(X, model).detach().cpu()\n",
    "            preds = [*preds, *[i for i in y_hat]]\n",
    "            trues = [*trues, *[i for i in monai.data.decollate_batch(y)]]\n",
    "    \n",
    "    for t in thresholds:\n",
    "        logit_process = monai.transforms.Compose([\n",
    "            monai.transforms.EnsureType(), \n",
    "            monai.transforms.Activations(softmax=True),\n",
    "            monai.transforms.AsDiscrete(threshold=t)\n",
    "        ])\n",
    "        metric_func([logit_process(i) for i in preds], trues)\n",
    "        metric = metric_func.aggregate().item()\n",
    "        metric_func.reset()\n",
    "        res.append((t.detach().cpu().item(), metric))\n",
    "\n",
    "    return sorted(res, key=lambda tpl: tpl[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cache_dir():\n",
    "    cache_dir = \"../data/cache_dir/additional_images/\"\n",
    "    os.system(f\"rm -rf {cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_denoised_model(model, organ, exp):\n",
    "    model_path = Path(f\"../logs/{exp}_denoising_pretraining/\").ls()\n",
    "    model_path = [p for p in model_path if f\"{organ}_transfered\" in p.name][0]\n",
    "    model_path = model_path/\"checkpoints\"/\"model.best.pth\"\n",
    "    return load_weights(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonaiSupervisedRunner(catalyst.dl.SupervisedRunner):\n",
    "    def forward(self, batch):\n",
    "        if self.is_train_loader:\n",
    "            output = {self._output_key: self.model(batch[self._input_key])}\n",
    "        elif self.is_valid_loader:\n",
    "            output = {\n",
    "                self._output_key: sw_infer(batch[self._input_key], self.model)\n",
    "            }\n",
    "        else: \n",
    "            assert False, \"This is not supposed to run...\"\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_log = {\"organ\": [], \"threshold\":[], \"train_dice\": [], \"valid_dice\": [], \"test_dice\": []}\n",
    "\n",
    "for organ in TRAIN_DF.organ.unique():\n",
    "    \n",
    "    # Decoder denoising pretraining:\n",
    "    #add_organ = organ if organ != \"largeintestine\" else \"colon\"\n",
    "    #ADDITIONAL_IMAGES = get_image_files(\"../data/additional_images/images\")\n",
    "    #ADDITIONAL_IMAGES = [fn for fn in ADDITIONAL_IMAGES if add_organ in fn.stem]\n",
    "    #add_idx = list(range(len(ADDITIONAL_IMAGES)))\n",
    "    #np.random.shuffle(add_idx)\n",
    "    #cutoff = int(0.8 * len(add_idx))\n",
    "    #ADD_TRAIN = ADDITIONAL_IMAGES[:cutoff]\n",
    "    #ADD_VALID = ADDITIONAL_IMAGES[cutoff:]\n",
    "    #data_dicts = {\n",
    "    #    \"train\": {i: {IMAGE: fn, LABEL: fn} for i, fn in enumerate(ADD_TRAIN)},\n",
    "    #    \"valid\": {i: {IMAGE: fn, LABEL: fn} for i, fn in enumerate(ADD_VALID)}\n",
    "    #}\n",
    "    #train_ds = monai.data.PersistentDataset(data_dicts[\"train\"], transform=get_noisy_transforms(), cache_dir=\"../data/cache_dir/additional_images\")\n",
    "    #valid_ds = monai.data.PersistentDataset(data_dicts[\"valid\"], transform=get_noisy_transforms(), cache_dir=\"../data/cache_dir/additional_images\")\n",
    "    #train_dl = monai.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    #valid_dl = monai.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    #loaders = {\"train\": train_dl, \"valid\": valid_dl}\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,        \n",
    "        encoder_weights=\"imagenet\",     \n",
    "        in_channels=3,                  \n",
    "        classes=3,  \n",
    "    )\n",
    "    model.segmentation_head = torch.nn.Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    model = load_denoised_model(model, organ, \"16\")\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    #criterion = SSIMLossWrapper()\n",
    "    #optimizer = Lookahead(torch.optim.RAdam([*model.decoder.parameters(), *model.segmentation_head.parameters()], lr=LR))\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5)\n",
    "    #callbacks = [\n",
    "    #    catalyst.dl.OptimizerCallback(\n",
    "    #        metric_key=\"loss\", \n",
    "    #        accumulation_steps=4),\n",
    "    #    catalyst.dl.EarlyStoppingCallback(\n",
    "    #        patience=EARLY_STOP_PATIENCE, \n",
    "    #        loader_key=\"valid\", \n",
    "    #        metric_key=\"loss\",\n",
    "    #        min_delta=1e-3,\n",
    "    #        minimize=True)\n",
    "    #]\n",
    "\n",
    "    #runner = catalyst.dl.SupervisedRunner(\n",
    "    #    input_key=IMAGE, \n",
    "    #    output_key=\"logits\", \n",
    "    #    target_key=LABEL, \n",
    "    #    loss_key=\"loss\"\n",
    "    #)\n",
    "\n",
    "    #runner.train(\n",
    "    #    model=model,\n",
    "    #    criterion=criterion,\n",
    "    #    optimizer=optimizer,\n",
    "    #    scheduler=scheduler,\n",
    "    #    loaders=loaders,\n",
    "    #    num_epochs=5,\n",
    "    #    callbacks=callbacks,\n",
    "    #    logdir=LOG_DIR/f\"{organ}_denoise\",\n",
    "    #    valid_loader=\"valid\",\n",
    "    #    valid_metric=\"loss\",\n",
    "    #    minimize_valid_metric=True,\n",
    "    #    verbose=True,\n",
    "    #    timeit=False,\n",
    "    #    load_best_on_end=False\n",
    "    #)\n",
    "    # Not enough disk space to keep caches\n",
    "    #empty_cache_dir()\n",
    "\n",
    "    # finetuning\n",
    "\n",
    "    organ_train_test_df = split_df_train_test(TRAIN_DF[TRAIN_DF.organ==organ],\"is_test\", test_pct=0.1)\n",
    "    organ_testset_df = organ_train_test_df[organ_train_test_df.is_test].copy()\n",
    "    organ_train_valid_df = organ_train_test_df[~organ_train_test_df.is_test].copy()\n",
    "    organ_train_valid_df = split_df_train_test(organ_train_valid_df, \"is_valid\", seed=92)\n",
    "    assert len(organ_testset_df.organ.unique()) == 1\n",
    "    assert len(organ_train_valid_df.organ.unique()) == 1\n",
    "    del organ_train_test_df\n",
    "\n",
    "    train_ids = organ_train_valid_df[~organ_train_valid_df.is_valid].id.values\n",
    "    valid_ids = organ_train_valid_df[organ_train_valid_df.is_valid].id.values\n",
    "    test_ids = organ_testset_df.id.values\n",
    "    assert len(set(train_ids).intersection(set(valid_ids))) == 0\n",
    "    assert len(set(train_ids).intersection(set(test_ids))) == 0\n",
    "    assert len(set(valid_ids).intersection(set(test_ids))) == 0\n",
    "\n",
    "    data_dicts = {\n",
    "        \"train\": {i: {IMAGE: fid, LABEL: fid} for i, fid in enumerate(train_ids)},\n",
    "        \"valid\": {i: {IMAGE: fid, LABEL: fid} for i, fid in enumerate(valid_ids)},\n",
    "        \"test\":  {i: {IMAGE: fid, LABEL: fid} for i, fid in enumerate(test_ids)}\n",
    "    }\n",
    "\n",
    "    train_ds = monai.data.CacheDataset(data_dicts[\"train\"], transform=get_train_transforms())\n",
    "    valid_ds = monai.data.CacheDataset(data_dicts[\"valid\"], transform=get_valid_transforms())\n",
    "    test_ds  = monai.data.CacheDataset(data_dicts[\"test\"],  transform=get_test_transforms())\n",
    "\n",
    "    train_dl = monai.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = monai.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_dl  = monai.data.DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    loaders = {\"train\": train_dl, \"valid\": valid_dl}\n",
    "\n",
    "    criterion = monai.losses.GeneralizedDiceFocalLoss(softmax=True)\n",
    "    optimizer = Lookahead(torch.optim.RAdam(model.parameters(), lr=LR))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5)\n",
    "\n",
    "    dice_func = partial(\n",
    "        calc_metric, \n",
    "        metric_func=monai.metrics.DiceMetric(include_background=False, reduction=\"mean\"))\n",
    "\n",
    "    callbacks = [\n",
    "        catalyst.dl.FunctionalMetricCallback(\n",
    "        input_key=\"logits\",\n",
    "        target_key=LABEL,\n",
    "        metric_fn=dice_func,\n",
    "        metric_key=\"dice\"\n",
    "        ),\n",
    "        catalyst.dl.OptimizerCallback(\n",
    "            metric_key=\"loss\", \n",
    "            accumulation_steps=ACCUM_STEPS),\n",
    "        catalyst.dl.EarlyStoppingCallback(\n",
    "            patience=EARLY_STOP_PATIENCE, \n",
    "            loader_key=\"valid\", \n",
    "            metric_key=\"loss\",\n",
    "            min_delta=1e-3,\n",
    "            minimize=True)\n",
    "    ]\n",
    "\n",
    "    runner = MonaiSupervisedRunner(\n",
    "        input_key=IMAGE, \n",
    "        output_key=\"logits\", \n",
    "        target_key=LABEL, \n",
    "        loss_key=\"loss\"\n",
    "    )\n",
    "\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loaders=loaders,\n",
    "        num_epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        logdir=LOG_DIR/f\"{organ}_finetuned\",\n",
    "        valid_loader=\"valid\",\n",
    "        valid_metric=\"loss\",\n",
    "        minimize_valid_metric=True,\n",
    "        verbose=False,\n",
    "        timeit=False,\n",
    "        load_best_on_end=True\n",
    "    )\n",
    "\n",
    "    dice_metric = monai.metrics.DiceMetric(\n",
    "        include_background=False, \n",
    "        reduction=\"mean\")\n",
    "\n",
    "    best_threshold, test_dice = get_best_threshold(model, test_dl, dice_metric) \n",
    "\n",
    "    train_dice = test_model(model, train_dl, metric_func=dice_metric)\n",
    "    valid_dice = test_model(model, valid_dl, metric_func=dice_metric)\n",
    "\n",
    "    metrics_log[\"organ\"].append(organ)\n",
    "    metrics_log[\"threshold\"].append(best_threshold)\n",
    "    metrics_log[\"train_dice\"].append(train_dice)\n",
    "    metrics_log[\"valid_dice\"].append(valid_dice)\n",
    "    metrics_log[\"test_dice\"].append(test_dice)\n",
    "    save_df(metrics_log, LOG_DIR/\"metrics.csv\", replace=True)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of submission model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hubmap_reboot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a41d83ab1b5d99694b0e2755cc1a9092b5b6bb1cb85044d4c03a072b08ac20f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
